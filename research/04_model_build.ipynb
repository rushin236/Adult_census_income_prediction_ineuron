{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\GitHub\\\\Ineuron_adult_census_income_prediction\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\GitHub\\\\Ineuron_adult_census_income_prediction'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelBuildConfig:\n",
    "    root_dir: Path\n",
    "    preprocessed_data_file: Path\n",
    "    preprocessor_file: Path\n",
    "    model_file: Path\n",
    "    model_results: Path\n",
    "    best_params: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adult_census.constants import *\n",
    "from adult_census.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config=CONFIG_FILE_PATH, params=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config)\n",
    "        self.params = read_yaml(params)\n",
    "\n",
    "    def get_model_build_config(self) -> ModelBuildConfig:\n",
    "        config = self.config.model_build\n",
    "\n",
    "        model_build_config = ModelBuildConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            preprocessed_data_file=config.preprocessed_data_file,\n",
    "            preprocessor_file=config.preprocessor_file,\n",
    "            model_file=config.model_file,\n",
    "            model_results=config.model_results,\n",
    "            best_params=config.best_params,\n",
    "        )\n",
    "\n",
    "        return model_build_config, self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adult_census.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for model training and evaluation\n",
    "\n",
    "\n",
    "def fit_model(model, x, y, parameters = None):\n",
    "    try:\n",
    "        if parameters != None:\n",
    "            gcv = GridSearchCV(estimator=model, param_grid=parameters, n_jobs=-1)\n",
    "            gcv.fit(X=x, y=y)\n",
    "            best_params = gcv.best_params_\n",
    "            model.set_params(**gcv.best_params_)\n",
    "            pred = model.predict(x)\n",
    "            result = classification_report(y, pred, output_dict=True)\n",
    "            return model, result, best_params\n",
    "        else:\n",
    "            model.fit(x, y)\n",
    "            pred = model.predict(x)\n",
    "            result = classification_report(y, pred, output_dict=True)\n",
    "            return model, result\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    models_dict = {\n",
    "        \"LogisticRegression\": LogisticRegression(),\n",
    "        \"SVC\": SVC(),\n",
    "        \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "        \"GaussianNB\": GaussianNB(),\n",
    "        \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "        \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "        \"AdaBoostClassifier\": AdaBoostClassifier(),\n",
    "        \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "        \"XGBClassifier\": XGBClassifier(),\n",
    "    }\n",
    "\n",
    "    return models_dict\n",
    "\n",
    "\n",
    "def get_train_test_split(df: pd.DataFrame):\n",
    "    X = df.drop(\"income\", axis=1)\n",
    "    y = df[\"income\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return [X_train, X_test, y_train, y_test]\n",
    "\n",
    "\n",
    "def get_report(result: dict):\n",
    "    cr = {}\n",
    "    cr[\"models\"] = []\n",
    "    cr[\"accuracy\"] = []\n",
    "    cr[\"macro avg precision\"] = []\n",
    "    cr[\"macro avg recall\"] = []\n",
    "    cr[\"macro avg f1-score\"] = []\n",
    "    cr[\"weighted avg precision\"] = []\n",
    "    cr[\"weighted avg recall\"] = []\n",
    "    cr[\"weighted avg f1-score\"] = []\n",
    "    for i, model in enumerate(result.keys()):\n",
    "        cr[\"models\"].append(model)\n",
    "        cr[\"accuracy\"].append(round(result[model][\"accuracy\"], 2))\n",
    "        cr[\"macro avg precision\"].append(\n",
    "            round(result[model][\"macro avg\"][\"precision\"], 2)\n",
    "        )\n",
    "        cr[\"macro avg recall\"].append(round(result[model][\"macro avg\"][\"recall\"], 2))\n",
    "        cr[\"macro avg f1-score\"].append(\n",
    "            round(result[model][\"macro avg\"][\"f1-score\"], 2)\n",
    "        )\n",
    "        cr[\"weighted avg precision\"].append(\n",
    "            round(result[model][\"weighted avg\"][\"precision\"], 2)\n",
    "        )\n",
    "        cr[\"weighted avg recall\"].append(\n",
    "            round(result[model][\"weighted avg\"][\"recall\"], 2)\n",
    "        )\n",
    "        cr[\"weighted avg f1-score\"].append(\n",
    "            round(result[model][\"weighted avg\"][\"f1-score\"], 2)\n",
    "        )\n",
    "        target_class = result[model].keys()\n",
    "        for each in target_class:\n",
    "            if each not in [\"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "                if i == 0:\n",
    "                    cr[each + \" \" + \"precision\"] = []\n",
    "                    cr[each + \" \" + \"recall\"] = []\n",
    "                    cr[each + \" \" + \"f1-score\"] = []\n",
    "\n",
    "                cr[each + \" \" + \"precision\"].append(\n",
    "                    round(result[model][each][\"precision\"], 2)\n",
    "                )\n",
    "                cr[each + \" \" + \"recall\"].append(\n",
    "                    round(result[model][each][\"recall\"], 2)\n",
    "                )\n",
    "                cr[each + \" \" + \"f1-score\"].append(\n",
    "                    round(result[model][each][\"f1-score\"], 2)\n",
    "                )\n",
    "\n",
    "    return pd.DataFrame(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuild:\n",
    "    def __init__(self, config: ModelBuildConfig, params):\n",
    "        self.config = config\n",
    "        self.params = params\n",
    "\n",
    "        create_directories([self.config.root_dir])\n",
    "\n",
    "    def get_data_preprocessor(self):\n",
    "        logger.info(\"Loading transformed data and preprocessor.\")\n",
    "\n",
    "        df = pd.read_csv(self.config.preprocessed_data_file)\n",
    "\n",
    "        with open(self.config.preprocessor_file, \"rb\") as f:\n",
    "            preprocessor = joblib.load(f)\n",
    "\n",
    "        logger.info(\"Transformed data and Preprocessor loading complete.\")\n",
    "\n",
    "        return df, preprocessor\n",
    "\n",
    "    def train_model(self, models_dict, X_train, y_train, parameters: bool = False):\n",
    "        try:\n",
    "            tr_models = {}\n",
    "            tr_results = {}\n",
    "\n",
    "            for model in models_dict.keys():\n",
    "                if (parameters == True) and (model in self.params.keys()):\n",
    "                    logger.info(f\"Hyperparameter tuning for {model} started.\")\n",
    "                    parameter_of_model = self.params[model]\n",
    "                    tr_model, result, best_params = fit_model(\n",
    "                        models_dict[model],\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        parameters=parameter_of_model,\n",
    "                    )\n",
    "\n",
    "                    logger.info(f\"Hyperparameter tuning for {model} completed.\")\n",
    "\n",
    "                    if (best_params != None) and (\n",
    "                        not os.path.exists(self.config.best_params)\n",
    "                    ):\n",
    "                        with open(self.config.best_params, \"w\") as f:\n",
    "                            f.write(f\"Best Params for {model}: \\n {best_params}\")\n",
    "                    else:\n",
    "                        with open(self.config.best_params, \"a\") as f:\n",
    "                            f.write(f\"\\n\\nBest Params for {model}: \\n {best_params}\")\n",
    "                else:\n",
    "                    logger.info(f\"Model training for {model} started.\")\n",
    "                    tr_model, result = fit_model(models_dict[model], X_train, y_train)\n",
    "                    logger.info(f\"Model training for {model} completed.\")\n",
    "\n",
    "                tr_models[model] = tr_model\n",
    "                tr_results[model] = result\n",
    "\n",
    "            return tr_models, tr_results\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def get_best_model(self, models_dict: dict, models_results: pd.DataFrame):\n",
    "        best_model = models_results.sort_values(\"accuracy\", ascending=False)[\n",
    "            \"models\"\n",
    "        ].to_list()[0]\n",
    "        best_model = models_dict[best_model]\n",
    "        return best_model\n",
    "\n",
    "    def save_results(self, results: dict):\n",
    "        try:\n",
    "            for result in results.keys():\n",
    "                res = results[result]\n",
    "                if not os.path.exists(self.config.model_results):\n",
    "                    with open(self.config.model_results, \"w\") as f:\n",
    "                        f.write(\n",
    "                            f\"Results for {result}: \\n{res.sort_values('accuracy', ascending=False).to_string()}\"\n",
    "                        )\n",
    "                else:\n",
    "                    with open(self.config.model_results, \"a\") as f:\n",
    "                        f.write(\n",
    "                            f\"\\nResults for {result}: \\n{res.sort_values('accuracy', ascending=False).to_string()}\"\n",
    "                        )\n",
    "\n",
    "            logger.info(f\"Model results saved to {self.config.model_results}\")\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def save_model(self, model):\n",
    "        try:\n",
    "            with open(self.config.model_file, \"wb\") as f:\n",
    "                joblib.dump(model, f)\n",
    "                logger.info(f\"Model saved to {self.config.model_file}\")\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-04 23:55:49,279]: INFO common yaml file: config\\config.yaml loads successfully\n",
      "[2024-02-04 23:55:49,285]: INFO common yaml file: params.yaml loads successfully\n",
      "[2024-02-04 23:55:49,287]: INFO common created directory at : artifacts/model_results\n",
      "[2024-02-04 23:55:49,288]: INFO 233220522 Loading transformed data and preprocessor.\n",
      "[2024-02-04 23:55:49,429]: INFO 233220522 Transformed data and Preprocessor loading complete.\n",
      "[2024-02-04 23:55:49,442]: INFO 233220522 Model training for LogisticRegression started.\n",
      "[2024-02-04 23:55:49,562]: INFO 233220522 Model training for LogisticRegression completed.\n",
      "[2024-02-04 23:55:49,563]: INFO 233220522 Model training for SVC started.\n",
      "[2024-02-04 23:56:28,405]: INFO 233220522 Model training for SVC completed.\n",
      "[2024-02-04 23:56:28,406]: INFO 233220522 Model training for KNeighborsClassifier started.\n",
      "[2024-02-04 23:56:29,994]: INFO 233220522 Model training for KNeighborsClassifier completed.\n",
      "[2024-02-04 23:56:29,995]: INFO 233220522 Model training for GaussianNB started.\n",
      "[2024-02-04 23:56:30,059]: INFO 233220522 Model training for GaussianNB completed.\n",
      "[2024-02-04 23:56:30,060]: INFO 233220522 Model training for DecisionTreeClassifier started.\n",
      "[2024-02-04 23:56:30,233]: INFO 233220522 Model training for DecisionTreeClassifier completed.\n",
      "[2024-02-04 23:56:30,234]: INFO 233220522 Model training for RandomForestClassifier started.\n",
      "[2024-02-04 23:56:32,853]: INFO 233220522 Model training for RandomForestClassifier completed.\n",
      "[2024-02-04 23:56:32,855]: INFO 233220522 Model training for AdaBoostClassifier started.\n",
      "[2024-02-04 23:56:33,979]: INFO 233220522 Model training for AdaBoostClassifier completed.\n",
      "[2024-02-04 23:56:33,980]: INFO 233220522 Model training for GradientBoostingClassifier started.\n",
      "[2024-02-04 23:56:36,743]: INFO 233220522 Model training for GradientBoostingClassifier completed.\n",
      "[2024-02-04 23:56:36,745]: INFO 233220522 Model training for XGBClassifier started.\n",
      "[2024-02-04 23:56:36,952]: INFO 233220522 Model training for XGBClassifier completed.\n",
      "[2024-02-04 23:56:36,954]: INFO 233220522 Hyperparameter tuning for LogisticRegression started.\n",
      "[2024-02-04 23:56:39,790]: INFO 233220522 Hyperparameter tuning for LogisticRegression completed.\n",
      "[2024-02-04 23:56:39,791]: INFO 233220522 Model training for SVC started.\n",
      "[2024-02-04 23:57:18,752]: INFO 233220522 Model training for SVC completed.\n",
      "[2024-02-04 23:57:18,753]: INFO 233220522 Hyperparameter tuning for KNeighborsClassifier started.\n",
      "[2024-02-04 23:57:30,439]: INFO 233220522 Hyperparameter tuning for KNeighborsClassifier completed.\n",
      "[2024-02-04 23:57:30,440]: INFO 233220522 Model training for GaussianNB started.\n",
      "[2024-02-04 23:57:30,505]: INFO 233220522 Model training for GaussianNB completed.\n",
      "[2024-02-04 23:57:30,506]: INFO 233220522 Hyperparameter tuning for DecisionTreeClassifier started.\n",
      "[2024-02-04 23:57:31,089]: INFO 233220522 Hyperparameter tuning for DecisionTreeClassifier completed.\n",
      "[2024-02-04 23:57:31,091]: INFO 233220522 Hyperparameter tuning for RandomForestClassifier started.\n",
      "[2024-02-04 23:57:43,705]: INFO 233220522 Hyperparameter tuning for RandomForestClassifier completed.\n",
      "[2024-02-04 23:57:43,707]: INFO 233220522 Hyperparameter tuning for AdaBoostClassifier started.\n",
      "[2024-02-04 23:57:47,771]: INFO 233220522 Hyperparameter tuning for AdaBoostClassifier completed.\n",
      "[2024-02-04 23:57:47,773]: INFO 233220522 Hyperparameter tuning for GradientBoostingClassifier started.\n",
      "[2024-02-04 23:57:57,552]: INFO 233220522 Hyperparameter tuning for GradientBoostingClassifier completed.\n",
      "[2024-02-04 23:57:57,553]: INFO 233220522 Model training for XGBClassifier started.\n",
      "[2024-02-04 23:57:57,759]: INFO 233220522 Model training for XGBClassifier completed.\n",
      "[2024-02-04 23:57:57,778]: INFO 233220522 Model results saved to artifacts/model_results/results.txt\n",
      "[2024-02-04 23:57:57,781]: INFO 233220522 Model saved to models/model.joblib\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_build_config, params = config.get_model_build_config()\n",
    "    model_build = ModelBuild(config=model_build_config, params=params)\n",
    "    df, preprocessor = model_build.get_data_preprocessor()\n",
    "    train_test_set = get_train_test_split(df=df)\n",
    "    models = get_models()\n",
    "    tr_models, tr_results = model_build.train_model(\n",
    "        models_dict=models, X_train=train_test_set[0], y_train=train_test_set[2]\n",
    "    )\n",
    "    tr_results = get_report(result=tr_results)\n",
    "    hy_models, hy_results = model_build.train_model(\n",
    "        models_dict=models,\n",
    "        X_train=train_test_set[0],\n",
    "        y_train=train_test_set[2],\n",
    "        parameters=True,\n",
    "    )\n",
    "    hy_results = get_report(result=hy_results)\n",
    "    best_model = model_build.get_best_model(hy_models, hy_results)\n",
    "    model_build.save_results(\n",
    "        {\"Trained Models\": tr_results, \"Tunned Models\": hy_results}\n",
    "    )\n",
    "    model_build.save_model(best_model)\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg precision</th>\n",
       "      <th>macro avg recall</th>\n",
       "      <th>macro avg f1-score</th>\n",
       "      <th>weighted avg precision</th>\n",
       "      <th>weighted avg recall</th>\n",
       "      <th>weighted avg f1-score</th>\n",
       "      <th>0 precision</th>\n",
       "      <th>0 recall</th>\n",
       "      <th>0 f1-score</th>\n",
       "      <th>1 precision</th>\n",
       "      <th>1 recall</th>\n",
       "      <th>1 f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       models  accuracy  macro avg precision  \\\n",
       "4      DecisionTreeClassifier      1.00                 1.00   \n",
       "5      RandomForestClassifier      1.00                 1.00   \n",
       "8               XGBClassifier      0.89                 0.87   \n",
       "2        KNeighborsClassifier      0.88                 0.85   \n",
       "1                         SVC      0.86                 0.82   \n",
       "6          AdaBoostClassifier      0.86                 0.82   \n",
       "7  GradientBoostingClassifier      0.86                 0.83   \n",
       "0          LogisticRegression      0.85                 0.80   \n",
       "3                  GaussianNB      0.64                 0.68   \n",
       "\n",
       "   macro avg recall  macro avg f1-score  weighted avg precision  \\\n",
       "4              1.00                1.00                    1.00   \n",
       "5              1.00                1.00                    1.00   \n",
       "8              0.83                0.85                    0.89   \n",
       "2              0.82                0.83                    0.88   \n",
       "1              0.76                0.79                    0.85   \n",
       "6              0.77                0.79                    0.85   \n",
       "7              0.78                0.80                    0.86   \n",
       "0              0.76                0.78                    0.84   \n",
       "3              0.74                0.62                    0.83   \n",
       "\n",
       "   weighted avg recall  weighted avg f1-score  0 precision  0 recall  \\\n",
       "4                 1.00                   1.00         1.00      1.00   \n",
       "5                 1.00                   1.00         1.00      1.00   \n",
       "8                 0.89                   0.89         0.91      0.95   \n",
       "2                 0.88                   0.88         0.91      0.94   \n",
       "1                 0.86                   0.85         0.88      0.94   \n",
       "6                 0.86                   0.85         0.88      0.94   \n",
       "7                 0.86                   0.86         0.88      0.94   \n",
       "0                 0.85                   0.84         0.88      0.93   \n",
       "3                 0.64                   0.66         0.97      0.54   \n",
       "\n",
       "   0 f1-score  1 precision  1 recall  1 f1-score  \n",
       "4        1.00         1.00      1.00        1.00  \n",
       "5        1.00         1.00      1.00        1.00  \n",
       "8        0.93         0.82      0.72        0.77  \n",
       "2        0.92         0.78      0.70        0.74  \n",
       "1        0.91         0.76      0.59        0.66  \n",
       "6        0.91         0.76      0.60        0.67  \n",
       "7        0.91         0.78      0.61        0.68  \n",
       "0        0.90         0.73      0.59        0.65  \n",
       "3        0.69         0.39      0.94        0.56  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_results.sort_values(\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg precision</th>\n",
       "      <th>macro avg recall</th>\n",
       "      <th>macro avg f1-score</th>\n",
       "      <th>weighted avg precision</th>\n",
       "      <th>weighted avg recall</th>\n",
       "      <th>weighted avg f1-score</th>\n",
       "      <th>0 precision</th>\n",
       "      <th>0 recall</th>\n",
       "      <th>0 f1-score</th>\n",
       "      <th>1 precision</th>\n",
       "      <th>1 recall</th>\n",
       "      <th>1 f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       models  accuracy  macro avg precision  \\\n",
       "4      DecisionTreeClassifier      1.00                 1.00   \n",
       "5      RandomForestClassifier      1.00                 1.00   \n",
       "8               XGBClassifier      0.89                 0.87   \n",
       "2        KNeighborsClassifier      0.88                 0.85   \n",
       "1                         SVC      0.86                 0.82   \n",
       "6          AdaBoostClassifier      0.86                 0.82   \n",
       "7  GradientBoostingClassifier      0.86                 0.83   \n",
       "0          LogisticRegression      0.85                 0.80   \n",
       "3                  GaussianNB      0.64                 0.68   \n",
       "\n",
       "   macro avg recall  macro avg f1-score  weighted avg precision  \\\n",
       "4              1.00                1.00                    1.00   \n",
       "5              1.00                1.00                    1.00   \n",
       "8              0.83                0.85                    0.89   \n",
       "2              0.82                0.83                    0.88   \n",
       "1              0.76                0.79                    0.85   \n",
       "6              0.77                0.79                    0.85   \n",
       "7              0.78                0.80                    0.86   \n",
       "0              0.76                0.78                    0.84   \n",
       "3              0.74                0.62                    0.83   \n",
       "\n",
       "   weighted avg recall  weighted avg f1-score  0 precision  0 recall  \\\n",
       "4                 1.00                   1.00         1.00      1.00   \n",
       "5                 1.00                   1.00         1.00      1.00   \n",
       "8                 0.89                   0.89         0.91      0.95   \n",
       "2                 0.88                   0.88         0.91      0.94   \n",
       "1                 0.86                   0.85         0.88      0.94   \n",
       "6                 0.86                   0.85         0.88      0.94   \n",
       "7                 0.86                   0.86         0.88      0.94   \n",
       "0                 0.85                   0.84         0.88      0.93   \n",
       "3                 0.64                   0.66         0.97      0.54   \n",
       "\n",
       "   0 f1-score  1 precision  1 recall  1 f1-score  \n",
       "4        1.00         1.00      1.00        1.00  \n",
       "5        1.00         1.00      1.00        1.00  \n",
       "8        0.93         0.82      0.72        0.77  \n",
       "2        0.92         0.78      0.70        0.74  \n",
       "1        0.91         0.76      0.59        0.66  \n",
       "6        0.91         0.76      0.60        0.67  \n",
       "7        0.91         0.78      0.61        0.68  \n",
       "0        0.90         0.73      0.59        0.65  \n",
       "3        0.69         0.39      0.94        0.56  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hy_results.sort_values(\"accuracy\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
